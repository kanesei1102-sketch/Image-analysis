import streamlit as st
import cv2
import numpy as np
import pandas as pd
import datetime  # JSTæ—¥æ™‚å–å¾—ç”¨

# ---------------------------------------------------------
# 0. ãƒšãƒ¼ã‚¸è¨­å®š
# ---------------------------------------------------------
st.set_page_config(page_title="Bio-Image Quantifier Pro (Final)", layout="wide")

if "analysis_history" not in st.session_state:
    st.session_state.analysis_history = []

# ---------------------------------------------------------
# 1. é–¢æ•°å®šç¾©
# ---------------------------------------------------------
COLOR_MAP = {
    "èŒ¶è‰² (DAB)": {"lower": np.array([10, 50, 20]), "upper": np.array([30, 255, 255])},
    "ç·‘ (GFP)": {"lower": np.array([35, 50, 50]), "upper": np.array([85, 255, 255])},
    "èµ¤ (RFP)": {"lower": np.array([0, 50, 50]), "upper": np.array([10, 255, 255])},
    "é’ (DAPI)": {"lower": np.array([100, 50, 50]), "upper": np.array([140, 255, 255])}
}

def get_mask(hsv_img, color_name, sens, bright_min):
    """é€šå¸¸ã®æŠ½å‡ºç”¨ãƒã‚¹ã‚¯"""
    if color_name == "èµ¤ (RFP)":
        lower1 = np.array([0, 30, bright_min])
        upper1 = np.array([10 + sens//2, 255, 255])
        lower2 = np.array([170 - sens//2, 30, bright_min])
        upper2 = np.array([180, 255, 255])
        return cv2.inRange(hsv_img, lower1, upper1) | cv2.inRange(hsv_img, lower2, upper2)
    else:
        conf = COLOR_MAP[color_name]
        l = np.clip(conf["lower"] - sens, 0, 255)
        u = np.clip(conf["upper"] + sens, 0, 255)
        l[2] = max(l[2], bright_min)
        return cv2.inRange(hsv_img, l, u)

def get_tissue_mask(hsv_img, color_name, sens, bright_min):
    """ã€çµ„ç¹”é¢ç©è¨ˆç®—ç”¨ã€‘ç©´åŸ‹ã‚å‡¦ç†ä»˜ããƒã‚¹ã‚¯"""
    mask = get_mask(hsv_img, color_name, sens, bright_min)
    kernel = np.ones((15, 15), np.uint8) 
    mask_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    cnts, _ = cv2.findContours(mask_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    mask_filled = np.zeros_like(mask)
    valid_tissue = [c for c in cnts if cv2.contourArea(c) > 500]
    cv2.drawContours(mask_filled, valid_tissue, -1, 255, thickness=cv2.FILLED)
    return mask_filled

def get_centroids(mask):
    """é‡å¿ƒå–å¾—ç”¨"""
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    pts = []
    for c in cnts:
        M = cv2.moments(c)
        if M["m00"] != 0:
            pts.append(np.array([M["m10"]/M["m00"], M["m01"]/M["m00"]]))
    return pts

# ---------------------------------------------------------
# 2. ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­è¨ˆ
# ---------------------------------------------------------
st.title("ğŸ”¬ Bio-Image Quantifier: Pro Edition")
st.caption("2025å¹´æœ€çµ‚ç‰ˆï¼šè§£æãƒ»ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå°‚ç”¨ (Scale: 1.5267 Î¼m/px)")

tab_main, tab_val = st.tabs(["ğŸš€ è§£æå®Ÿè¡Œ (Image Analysis)", "ğŸ† æ€§èƒ½è¨¼æ˜ (Validation Report)"])

# ---------------------------------------------------------
# 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# ---------------------------------------------------------
with st.sidebar:
    st.markdown("### ã€Notice / ã”æ¡ˆå†…ã€‘")
    st.info("""
    This tool is a beta version. If you plan to use results from this tool in your publications or conference presentations, **please contact the developer (Seiji Kaneko) in advance.**

    æœ¬ãƒ„ãƒ¼ãƒ«ã¯ç¾åœ¨é–‹ç™ºä¸­ã®ãƒ™ãƒ¼ã‚¿ç‰ˆã§ã™ã€‚è«–æ–‡æ²è¼‰ã‚„å­¦ä¼šç™ºè¡¨ç­‰ã«ä½¿ç”¨ã•ã‚Œã‚‹éš›ã¯ã€**äº‹å‰ã«é–‹ç™ºè€…ï¼ˆé‡‘å­ï¼‰ã¾ã§å¿…ãšä¸€å ±ãã ã•ã„ã€‚**

    ğŸ‘‰ **[Contact & Feedback Form / é€£çµ¡çª“å£](https://forms.gle/xgNscMi3KFfWcuZ1A)**

    We will provide guidance on validation support and proper acknowledgments/co-authorship.
    ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚µãƒãƒ¼ãƒˆã‚„ã€è¬è¾ãƒ»å…±è‘—ã®è¨˜è¼‰ã«ã¤ã„ã¦ã”æ¡ˆå†…ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚
    """)
    st.divider()

    st.header("Analysis Recipe")
    mode = st.selectbox("è§£æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ:", [
        "1. å˜è‰²é¢ç©ç‡ (Area)",
        "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)",
        "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)",
        "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)",
        "5. å‰²åˆãƒˆãƒ¬ãƒ³ãƒ‰è§£æ (Ratio Analysis)"
    ])
    st.divider()

    # ãƒ¢ãƒ¼ãƒ‰åˆ¥è¨­å®š
    if mode == "5. å‰²åˆãƒˆãƒ¬ãƒ³ãƒ‰è§£æ (Ratio Analysis)":
        st.markdown("### ğŸ”¢ æ¡ä»¶è¨­å®š (Batch)")
        trend_metric = st.radio("æ¸¬å®šå¯¾è±¡:", ["å…±å±€åœ¨ç‡ (Colocalization)", "é¢ç©ç‡ (Area)"])
        ratio_val = st.number_input("æ¡ä»¶å€¤:", value=0, step=10)
        ratio_unit = st.text_input("å˜ä½:", value="%", key="unit")
        sample_group = f"{ratio_val}{ratio_unit}"
        if trend_metric == "å…±å±€åœ¨ç‡ (Colocalization)":
            c1, c2 = st.columns(2)
            with c1:
                target_a = st.selectbox("CH-A (åŸºæº–):", list(COLOR_MAP.keys()), index=3) 
                sens_a = st.slider("Aæ„Ÿåº¦", 5, 50, 20, key="t_s_a")
                bright_a = st.slider("Aè¼åº¦", 0, 255, 60, key="t_b_a")
            with c2:
                target_b = st.selectbox("CH-B (å¯¾è±¡):", list(COLOR_MAP.keys()), index=2) 
                sens_b = st.slider("Bæ„Ÿåº¦", 5, 50, 20, key="t_s_b")
                bright_b = st.slider("Bè¼åº¦", 0, 255, 60, key="t_b_b")
        else:
            target_a = st.selectbox("è§£æè‰²:", list(COLOR_MAP.keys()), index=2)
            sens_a = st.slider("æ„Ÿåº¦", 5, 50, 20, key="t_s_a")
            bright_a = st.slider("è¼åº¦", 0, 255, 60, key="t_b_a")
    else:
        sample_group = st.text_input("ã‚°ãƒ«ãƒ¼ãƒ—å (Xè»¸):", value="Control")
        if mode == "1. å˜è‰²é¢ç©ç‡ (Area)":
            target_a = st.selectbox("è§£æè‰²:", list(COLOR_MAP.keys()))
            sens_a = st.slider("æ„Ÿåº¦", 5, 50, 20)
            bright_a = st.slider("è¼åº¦", 0, 255, 60)
        elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
            min_size = st.slider("æœ€å°ã‚µã‚¤ã‚º(px)", 10, 500, 50)
            bright_count = st.slider("ç´°èƒè¼åº¦ã—ãã„å€¤", 0, 255, 50)
            use_roi_norm = st.checkbox("çµ„ç¹”ã‚¨ãƒªã‚¢(CK8ãªã©)ã§å¯†åº¦ã‚’è¨ˆç®—ã™ã‚‹", value=True)
            if use_roi_norm:
                roi_color = st.selectbox("çµ„ç¹”ã®è‰²:", list(COLOR_MAP.keys()), index=2) 
                sens_roi = st.slider("çµ„ç¹”æ„Ÿåº¦", 5, 50, 20)
                bright_roi = st.slider("çµ„ç¹”è¼åº¦", 0, 255, 40)
        elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)":
            c1, c2 = st.columns(2)
            with c1:
                target_a = st.selectbox("CH-A:", list(COLOR_MAP.keys()), index=3)
                sens_a = st.slider("Aæ„Ÿåº¦", 5, 50, 20)
                bright_a = st.slider("Aè¼åº¦", 0, 255, 60)
            with c2:
                target_b = st.selectbox("CH-B:", list(COLOR_MAP.keys()), index=2)
                sens_b = st.slider("Bæ„Ÿåº¦", 5, 50, 20)
                bright_b = st.slider("Bè¼åº¦", 0, 255, 60)
        elif mode == "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
            target_a = st.selectbox("èµ·ç‚¹A:", list(COLOR_MAP.keys()), index=2)
            target_b = st.selectbox("å¯¾è±¡B:", list(COLOR_MAP.keys()), index=3)
            sens_common = st.slider("è‰²æ„Ÿåº¦", 5, 50, 20)
            bright_common = st.slider("è¼åº¦", 0, 255, 60)

    st.divider()
    with st.expander("ğŸ“ Calibration", expanded=True):
        scale_val = st.number_input("1pxã®é•·ã• (Î¼m/px)", value=1.5267, format="%.4f")
    if st.button("å±¥æ­´ã‚’å…¨æ¶ˆå»"):
        st.session_state.analysis_history = []
        st.rerun()

    st.divider()
    st.caption("ã€å…è²¬äº‹é … / Disclaimerã€‘")
    st.caption("""
    æœ¬ãƒ„ãƒ¼ãƒ«ã¯ç”»åƒè§£æã®è£œåŠ©ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
    ç…§æ˜æ¡ä»¶ã‚„è¨­å®šã«ã‚ˆã‚ŠçµæœãŒå¤‰å‹•ã™ã‚‹ãŸã‚ã€æœ€çµ‚çš„ãªè§£é‡ˆãŠã‚ˆã³çµè«–ã«ã¤ã„ã¦ã¯ã€
    åˆ©ç”¨è€…ãŒå°‚é–€çš„çŸ¥è¦‹ã«åŸºã¥ã„ã¦åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
    """)

# ---------------------------------------------------------
# 4. ã‚¿ãƒ–å†…å®¹ã®å®Ÿè£…
# ---------------------------------------------------------

# --- TAB 1: è§£æå®Ÿè¡Œç”»é¢ ---
with tab_main:
    uploaded_files = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "tif"], accept_multiple_files=True)
    if uploaded_files:
        st.success(f"{len(uploaded_files)} æšã®ç”»åƒã‚’è§£æä¸­...")
        batch_results = []
        for i, file in enumerate(uploaded_files):
            file.seek(0)
            file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
            img_raw = cv2.imdecode(file_bytes, cv2.IMREAD_UNCHANGED)
            if img_raw is not None:
                if img_raw.dtype == np.uint16 or img_raw.max() > 255:
                    p_min, p_max = np.percentile(img_raw, (0, 98))
                    img_8bit = np.clip((img_raw - p_min) * (255.0 / (p_max - p_min + 1e-5)), 0, 255).astype(np.uint8)
                    img_bgr = cv2.cvtColor(img_8bit, cv2.COLOR_GRAY2BGR) if len(img_8bit.shape) == 2 else img_8bit
                else:
                    img_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
                img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
                img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
                val, unit, res_display = 0.0, "", img_rgb.copy()
                
                # ã‚¹ã‚±ãƒ¼ãƒ«è¨ˆç®—ç”¨ã®è¦–é‡é¢ç©
                fov_area_mm2 = 0.0
                if scale_val > 0:
                    h, w = img_rgb.shape[:2]
                    fov_area_mm2 = (h * w) * ((scale_val / 1000) ** 2)

                # --- Mode 1: Area ---
                if mode == "1. å˜è‰²é¢ç©ç‡ (Area)" or (mode.startswith("5.") and trend_metric == "é¢ç©ç‡ (Area)"):
                    mask = get_mask(img_hsv, target_a, sens_a, bright_a)
                    val = (cv2.countNonZero(mask) / (img_rgb.shape[0] * img_rgb.shape[1])) * 100
                    unit, res_display = "% Area", cv2.merge([np.zeros_like(mask), mask, np.zeros_like(mask)])
                    real_area_str = ""
                    if fov_area_mm2 > 0:
                        real_area = fov_area_mm2 * (val / 100)
                        real_area_str = f"{real_area:.4f} mmÂ²"

                # --- Mode 2: Count ---
                elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
                    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                    _, th = cv2.threshold(gray, bright_count, 255, cv2.THRESH_BINARY)
                    blur = cv2.GaussianBlur(gray, (5,5), 0)
                    _, otsu = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                    final = cv2.bitwise_and(th, otsu)
                    cnts, _ = cv2.findContours(final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    valid = [c for c in cnts if cv2.contourArea(c) > min_size]
                    val, unit = len(valid), "cells"
                    cv2.drawContours(res_display, valid, -1, (0,255,0), 2)
                    
                    # å¯†åº¦è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¾©å…ƒï¼‰
                    density_str = ""
                    if scale_val > 0:
                        if 'use_roi_norm' in locals() and use_roi_norm:
                            mask_roi = get_tissue_mask(img_hsv, roi_color, sens_roi, bright_roi)
                            roi_pixel_count = cv2.countNonZero(mask_roi)
                            real_roi_area_mm2 = roi_pixel_count * ((scale_val / 1000) ** 2)
                            if real_roi_area_mm2 > 0:
                                density = val / real_roi_area_mm2
                                density_str = f"{int(density):,} cells/mmÂ² (ROI)"
                                roi_cnts, _ = cv2.findContours(mask_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                                cv2.drawContours(res_display, roi_cnts, -1, (255,0,0), 3) 
                            else:
                                density_str = "ROI Area 0"
                        elif fov_area_mm2 > 0:
                            density = val / fov_area_mm2
                            density_str = f"{int(density):,} cells/mmÂ² (FOV)"

                # --- Mode 3: Coloc ---
                elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)" or (mode.startswith("5.") and trend_metric == "å…±å±€åœ¨ç‡ (Colocalization)"):
                    mask_a = get_mask(img_hsv, target_a, sens_a, bright_a)
                    mask_b = get_mask(img_hsv, target_b, sens_b, bright_b)
                    coloc = cv2.bitwise_and(mask_a, mask_b)
                    denom = cv2.countNonZero(mask_a)
                    val, unit, res_display = (cv2.countNonZero(coloc)/denom*100) if denom > 0 else 0, "% Coloc", cv2.merge([mask_b, mask_a, np.zeros_like(mask_a)])

                # --- Mode 4: Distance ---
                elif mode == "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
                    mask_a, mask_b = get_mask(img_hsv, target_a, sens_common, bright_common), get_mask(img_hsv, target_b, sens_common, bright_common)
                    pts_a, pts_b = get_centroids(mask_a), get_centroids(mask_b)
                    if pts_a and pts_b:
                        val_px = np.mean([np.min([np.linalg.norm(pa - pb) for pb in pts_b]) for pa in pts_a])
                        val, unit = (val_px * scale_val) if scale_val > 0 else val_px, "Î¼m Dist" if scale_val > 0 else "px Dist"
                    res_display = cv2.addWeighted(img_rgb, 0.6, cv2.merge([mask_a, mask_b, np.zeros_like(mask_a)]), 0.4, 0)
                
                batch_results.append({"Image_Name": file.name, "Group": sample_group, "Value": max(0, val), "Unit": unit, "Is_Trend": mode.startswith("5."), "Ratio_Value": ratio_val if mode.startswith("5.") else 0})
                
                with st.expander(f"ğŸ“· {file.name}"):
                    st.write(f"Result: **{val:.2f} {unit}**")
                    # è¨ˆç®—çµæœã®è¡¨ç¤ºï¼ˆå¾©å…ƒï¼‰
                    if mode == "1. å˜è‰²é¢ç©ç‡ (Area)" and scale_val > 0 and 'real_area_str' in locals():
                         st.metric("å®Ÿçµ„ç¹”é¢ç©", real_area_str)
                    if mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)" and scale_val > 0 and 'density_str' in locals():
                        st.metric("å¯†åº¦", density_str)
                    
                    c1, c2 = st.columns(2)
                    c1.image(img_rgb, use_container_width=True)
                    c2.image(res_display, use_container_width=True)

        if st.button(f"ãƒ‡ãƒ¼ã‚¿ {len(batch_results)} ä»¶ã‚’è¿½åŠ "):
            st.session_state.analysis_history.extend(batch_results); st.rerun()
    if st.session_state.analysis_history:
        st.divider(); df_exp = pd.DataFrame(st.session_state.analysis_history); st.dataframe(df_exp)
        csv = df_exp.to_csv(index=False).encode('utf-8'); st.download_button("ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, f"quantified_data.csv", "text/csv")

# --- TAB 2: æ€§èƒ½ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ ---
with tab_val:
    st.header("ğŸ† æ€§èƒ½ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»æœ€çµ‚å ±å‘Š")
    st.markdown("""
    **æ¤œè¨¼ã‚½ãƒ¼ã‚¹:** [Broad Bioimage Benchmark Collection (BBBC005)](https://bbbc.broadinstitute.org/BBBC005)
    
    **å®šç¾©:** W1=ç´°èƒæ ¸ (Hoechst), W2=ç´°èƒä½“ (Phalloidin)
    """)

    m1, m2, m3 = st.columns(3)
    m1.metric("æ ¸ã‚«ã‚¦ãƒ³ãƒˆå¹³å‡ç²¾åº¦ (W1)", "95.8%", "Â±2% Stability")
    m2.metric("çµ±è¨ˆçš„ç·šå½¢æ€§ (RÂ²)", "0.9994", "Perfect Correlation")
    m3.metric("é€£ç¶šå‡¦ç†å®‰å®šæ€§", "800+ æš", "Error Rate: 0%")

    st.divider()

    st.subheader("ğŸ“ˆ 1. è¨ˆæ•°èƒ½åŠ›ã®æ•°å­¦çš„è¨¼æ˜ (Linearity)")
    c1, c2 = st.columns([1, 2])
    with c1:
        st.write("#### çµ±è¨ˆè©³ç´° (W1: Nuclei)")
        st.write("- **ç›¸é–¢ä¿‚æ•° (r):** 0.9997")
        st.write("- **å›å¸°å¼:** y = 0.88x + 2.11")
        st.info("ç´°èƒå¯†åº¦ãŒå¤‰ã‚ã£ã¦ã‚‚ 99.9% ã®ç›¸é–¢ã§æ­£ç¢ºã«è¿½å¾“ã€‚")
    with c2:
        try: st.image("final_linearity_summary.png", caption="Ground Truth vs Measured (Linearity)")
        except: st.warning("ğŸ“Š ç”»åƒ(final_linearity_summary.png)ã‚’é…ç½®ã—ã¦ãã ã•ã„")

    st.divider()

    st.subheader("ğŸ“Š 2. å¯†åº¦åˆ¥ãƒ»ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥ç²¾åº¦æ¯”è¼ƒ")
    c3, c4 = st.columns([2, 1])
    with c3:
        try: st.image("channel_accuracy_summary.png", caption="Channel Accuracy Comparison")
        except: st.warning("ğŸ“Š ç”»åƒ(channel_accuracy_summary.png)ã‚’é…ç½®ã—ã¦ãã ã•ã„")
    with c4:
        st.success("W1ï¼ˆæ ¸ï¼‰ã¯å…¨å¯†åº¦ã§90%ä»¥ä¸Šã‚’ç¶­æŒã€‚")
        st.warning("W2ï¼ˆç´°èƒä½“ï¼‰ã¯é«˜å¯†åº¦ä¸‹ã§éå‰°æ¤œå‡ºï¼ˆ120%ï¼‰ã‚’ç¢ºèªã€‚")

    st.divider()

    st.subheader("ğŸ“‰ 3. å…‰å­¦çš„ãªå …ç‰¢æ€§ (Focus Robustness)")
    try: st.image("accuracy_decay_final.png", caption="Accuracy Stability vs Image Blur")
    except: st.warning("ğŸ“Š ç”»åƒ(accuracy_decay_final.png)ã‚’é…ç½®ã—ã¦ãã ã•ã„")
    st.info("ğŸ’¡ **å‹•ä½œä¿è¨¼:** Focus Level 20ä»¥å†…ã§ã‚ã‚Œã°ã€ç²¾åº¦ 90% ä»¥ä¸Šã§ã®è§£æãŒå¯èƒ½ã§ã™ã€‚")
