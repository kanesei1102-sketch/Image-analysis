import streamlit as st
import cv2
import numpy as np
import pandas as pd
import datetime  # JSTæ—¥æ™‚å–å¾—ç”¨

# ---------------------------------------------------------
# 0. ãƒšãƒ¼ã‚¸è¨­å®š
# ---------------------------------------------------------
st.set_page_config(page_title="Bio-Image Quantifier Pro (Final)", layout="wide")

if "analysis_history" not in st.session_state:
    st.session_state.analysis_history = []

# ---------------------------------------------------------
# 1. é–¢æ•°å®šç¾©
# ---------------------------------------------------------
COLOR_MAP = {
    "èŒ¶è‰² (DAB)": {"lower": np.array([10, 50, 20]), "upper": np.array([30, 255, 255])},
    "ç·‘ (GFP)": {"lower": np.array([35, 50, 50]), "upper": np.array([85, 255, 255])},
    "èµ¤ (RFP)": {"lower": np.array([0, 50, 50]), "upper": np.array([10, 255, 255])},
    "é’ (DAPI)": {"lower": np.array([100, 50, 50]), "upper": np.array([140, 255, 255])}
}

def get_mask(hsv_img, color_name, sens, bright_min):
    """é€šå¸¸ã®æŠ½å‡ºç”¨ãƒã‚¹ã‚¯ï¼ˆç´°èƒã‚«ã‚¦ãƒ³ãƒˆç”¨ï¼‰"""
    if color_name == "èµ¤ (RFP)":
        lower1 = np.array([0, 30, bright_min])
        upper1 = np.array([10 + sens//2, 255, 255])
        lower2 = np.array([170 - sens//2, 30, bright_min])
        upper2 = np.array([180, 255, 255])
        return cv2.inRange(hsv_img, lower1, upper1) | cv2.inRange(hsv_img, lower2, upper2)
    else:
        conf = COLOR_MAP[color_name]
        l = np.clip(conf["lower"] - sens, 0, 255)
        u = np.clip(conf["upper"] + sens, 0, 255)
        l[2] = max(l[2], bright_min)
        return cv2.inRange(hsv_img, l, u)

def get_tissue_mask(hsv_img, color_name, sens, bright_min):
    """ã€çµ„ç¹”é¢ç©è¨ˆç®—ç”¨ã€‘ç©´åŸ‹ã‚å‡¦ç†ä»˜ããƒã‚¹ã‚¯"""
    # 1. åŸºæœ¬çš„ãªè‰²æŠ½å‡º
    mask = get_mask(hsv_img, color_name, sens, bright_min)
    
    # 2. ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—ï¼ˆã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ï¼‰ã§éš™é–“ã‚’åŸ‹ã‚ã‚‹
    kernel = np.ones((15, 15), np.uint8) 
    mask_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    
    # 3. ã•ã‚‰ã«è¼ªéƒ­å†…éƒ¨ã‚’å¡—ã‚Šã¤ã¶ã™ï¼ˆFill Holesï¼‰
    cnts, _ = cv2.findContours(mask_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    mask_filled = np.zeros_like(mask)
    # ã‚ã‚‹ç¨‹åº¦å¤§ãã„å¡Šã ã‘ã‚’çµ„ç¹”ã¨ã¿ãªã™ï¼ˆå¾®å°ãƒã‚¤ã‚ºé™¤å»ï¼‰
    valid_tissue = [c for c in cnts if cv2.contourArea(c) > 500]
    cv2.drawContours(mask_filled, valid_tissue, -1, 255, thickness=cv2.FILLED)
    
    return mask_filled

def get_centroids(mask):
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    pts = []
    for c in cnts:
        M = cv2.moments(c)
        if M["m00"] != 0:
            pts.append(np.array([M["m10"]/M["m00"], M["m01"]/M["m00"]]))
    return pts

# ---------------------------------------------------------
# 2. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# ---------------------------------------------------------
with st.sidebar:
    st.markdown("### ã€Notice / ã”æ¡ˆå†…ã€‘")
    st.info("""
    This tool is a beta version. If you plan to use results from this tool in your publications or conference presentations, **please contact the developer (Seiji Kaneko) in advance.**

    æœ¬ãƒ„ãƒ¼ãƒ«ã¯ç¾åœ¨é–‹ç™ºä¸­ã®ãƒ™ãƒ¼ã‚¿ç‰ˆã§ã™ã€‚è«–æ–‡æ²è¼‰ã‚„å­¦ä¼šç™ºè¡¨ç­‰ã«ä½¿ç”¨ã•ã‚Œã‚‹éš›ã¯ã€**äº‹å‰ã«é–‹ç™ºè€…ï¼ˆé‡‘å­ï¼‰ã¾ã§å¿…ãšä¸€å ±ãã ã•ã„ã€‚**

    ğŸ‘‰ **[Contact & Feedback Form / é€£çµ¡çª“å£](https://forms.gle/xgNscMi3KFfWcuZ1A)**

    We will provide guidance on validation support and proper acknowledgments/co-authorship.
    ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚µãƒãƒ¼ãƒˆã‚„ã€è¬è¾ãƒ»å…±è‘—ã®è¨˜è¼‰ã«ã¤ã„ã¦ã”æ¡ˆå†…ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚
    """)
    st.divider()

    st.header("Analysis Recipe")
    mode = st.selectbox("è§£æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ:", [
        "1. å˜è‰²é¢ç©ç‡ (Area)",
        "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)",
        "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)",
        "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)",
        "5. å‰²åˆãƒˆãƒ¬ãƒ³ãƒ‰è§£æ (Ratio Analysis)"
    ])
    st.divider()

    # --- ãƒ¢ãƒ¼ãƒ‰åˆ¥è¨­å®š ---
    if mode == "5. å‰²åˆãƒˆãƒ¬ãƒ³ãƒ‰è§£æ (Ratio Analysis)":
        st.markdown("### ğŸ”¢ æ¡ä»¶è¨­å®š (Batch)")
        trend_metric = st.radio("æ¸¬å®šå¯¾è±¡:", ["å…±å±€åœ¨ç‡ (Colocalization)", "é¢ç©ç‡ (Area)"])
        ratio_val = st.number_input("ä»Šå›ã®æ•°å€¤æ¡ä»¶ (å‰²åˆ/æ¿ƒåº¦):", value=0, step=10)
        ratio_unit = st.text_input("å˜ä½:", value="%", key="unit")
        sample_group = f"{ratio_val}{ratio_unit}"
        st.info(f"ãƒ©ãƒ™ãƒ«: **{sample_group}**")
        st.divider()
        if trend_metric == "å…±å±€åœ¨ç‡ (Colocalization)":
            c1, c2 = st.columns(2)
            with c1:
                target_a = st.selectbox("CH-A (åŸºæº–):", list(COLOR_MAP.keys()), index=3) 
                sens_a = st.slider("Aæ„Ÿåº¦", 5, 50, 20, key="t_s_a")
                bright_a = st.slider("Aè¼åº¦", 0, 255, 60, key="t_b_a")
            with c2:
                target_b = st.selectbox("CH-B (å¯¾è±¡):", list(COLOR_MAP.keys()), index=2) 
                sens_b = st.slider("Bæ„Ÿåº¦", 5, 50, 20, key="t_s_b")
                bright_b = st.slider("Bè¼åº¦", 0, 255, 60, key="t_b_b")
        else:
            target_a = st.selectbox("è§£æè‰²:", list(COLOR_MAP.keys()), index=2)
            sens_a = st.slider("æ„Ÿåº¦", 5, 50, 20, key="t_s_a")
            bright_a = st.slider("è¼åº¦", 0, 255, 60, key="t_b_a")
    else:
        sample_group = st.text_input("ã‚°ãƒ«ãƒ¼ãƒ—å (Xè»¸):", value="Control")
        st.divider()
        if mode == "1. å˜è‰²é¢ç©ç‡ (Area)":
            target_a = st.selectbox("è§£æè‰²:", list(COLOR_MAP.keys()))
            sens_a = st.slider("æ„Ÿåº¦", 5, 50, 20)
            bright_a = st.slider("è¼åº¦", 0, 255, 60)
        
        elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
            min_size = st.slider("æœ€å°ã‚µã‚¤ã‚º(px)", 10, 500, 50)
            bright_count = st.slider("ç´°èƒè¼åº¦ã—ãã„å€¤", 0, 255, 50)
            
            # --- â˜…çµ„ç¹”ã‚¨ãƒªã‚¢æ­£è¦åŒ–è¨­å®š ---
            st.divider()
            use_roi_norm = st.checkbox("çµ„ç¹”ã‚¨ãƒªã‚¢(CK8ãªã©)ã§å¯†åº¦ã‚’è¨ˆç®—ã™ã‚‹", value=True)
            if use_roi_norm:
                # ã€é‡è¦ã€‘è­¦å‘Šæ–‡ã®è¿½åŠ 
                st.markdown("""
                :red[**å®Ÿéš›ã®æŸ“è‰²ã«ç”¨ã„ãŸè‰²ã‚’ãŠé¸ã³ãã ã•ã„ã€‚ãã®ä»–ã®è‰²ã§è§£æã—ã‚ˆã†ã¨ã™ã‚‹ã¨ãƒã‚¤ã‚ºãŒå½±éŸ¿ã‚’åŠã¼ã—ã€æ­£ç¢ºãªç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆãŒè¡Œãˆã¾ã›ã‚“ã€‚**]
                """)
                
                roi_color = st.selectbox("çµ„ç¹”ã®è‰² (åˆ†æ¯):", list(COLOR_MAP.keys()), index=2) 
                sens_roi = st.slider("çµ„ç¹”æ„Ÿåº¦", 5, 50, 20, key="roi_sens")
                bright_roi = st.slider("çµ„ç¹”è¼åº¦", 0, 255, 40, key="roi_bright")

        elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)":
            c1, c2 = st.columns(2)
            with c1:
                target_a = st.selectbox("CH-A (åŸºæº–):", list(COLOR_MAP.keys()), index=3)
                sens_a = st.slider("Aæ„Ÿåº¦", 5, 50, 20)
                bright_a = st.slider("Aè¼åº¦", 0, 255, 60)
            with c2:
                target_b = st.selectbox("CH-B (å¯¾è±¡):", list(COLOR_MAP.keys()), index=2)
                sens_b = st.slider("Bæ„Ÿåº¦", 5, 50, 20)
                bright_b = st.slider("Bè¼åº¦", 0, 255, 60)
        elif mode == "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
            target_a = st.selectbox("èµ·ç‚¹A:", list(COLOR_MAP.keys()), index=2)
            target_b = st.selectbox("å¯¾è±¡B:", list(COLOR_MAP.keys()), index=3)
            sens_common = st.slider("è‰²æ„Ÿåº¦", 5, 50, 20)
            bright_common = st.slider("è¼åº¦", 0, 255, 60)

    # --- ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š ---
    st.divider()
    with st.expander("ğŸ“ ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š (Calibration)", expanded=True):
        st.caption("1ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Šã®å®Ÿå¯¸ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€é¢ç©(mmÂ²)ã‚„å¯†åº¦(cells/mmÂ²)ã‚’è‡ªå‹•ç®—å‡ºã—ã¾ã™ã€‚")
        # â˜…åˆæœŸå€¤: 1.5267
        scale_val = st.number_input("1pxã®é•·ã• (Î¼m/px)", value=1.5267, step=0.1, format="%.4f", help="0ã®å ´åˆã€ãƒ”ã‚¯ã‚»ãƒ«å˜ä½ã®ã¿ã§è¨ˆç®—ã—ã¾ã™")

    if st.button("å±¥æ­´ã‚’å…¨æ¶ˆå»"):
        st.session_state.analysis_history = []
        st.rerun()

    st.divider()
    st.caption("ã€å…è²¬äº‹é … / Disclaimerã€‘")
    st.caption("""
    æœ¬ãƒ„ãƒ¼ãƒ«ã¯ç”»åƒè§£æã®è£œåŠ©ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
    ç…§æ˜æ¡ä»¶ã‚„è¨­å®šã«ã‚ˆã‚ŠçµæœãŒå¤‰å‹•ã™ã‚‹ãŸã‚ã€æœ€çµ‚çš„ãªè§£é‡ˆãŠã‚ˆã³çµè«–ã«ã¤ã„ã¦ã¯ã€
    åˆ©ç”¨è€…ãŒå°‚é–€çš„çŸ¥è¦‹ã«åŸºã¥ã„ã¦åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
 
    This tool is for assistive purposes. Final interpretations should be 
    made by the user based on professional expertise.
    """)

# ---------------------------------------------------------
# 3. ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
# ---------------------------------------------------------
st.title("ğŸ”¬ Bio-Image Quantifier: Pro Edition")
st.caption("2025å¹´æœ€çµ‚ç‰ˆï¼šè§£æãƒ»ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå°‚ç”¨ (Scale: 1.5267 Î¼m/px)")

uploaded_files = st.file_uploader("ç”»åƒã‚’ã¾ã¨ã‚ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "tif"], accept_multiple_files=True)

if uploaded_files:
    st.success(f"{len(uploaded_files)} æšã®ç”»åƒã‚’è§£æä¸­...")
    batch_results = []
    
    for i, file in enumerate(uploaded_files):
        file.seek(0)
        file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
        
        # =========================================================
        # â˜…ã€16-bitå¯¾å¿œï¼†ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã€‘
        # =========================================================
        # 1. ã¾ãšã¯ã€Œãã®ã¾ã¾(UNCHANGED)ã€èª­ã¿è¾¼ã‚€
        img_raw = cv2.imdecode(file_bytes, cv2.IMREAD_UNCHANGED)
        
        if img_raw is not None:
            # 2. 16-bit (uint16) ã¾ãŸã¯ 8-bitè¶…ã®è¼åº¦ãŒã‚ã‚‹å ´åˆ
            if img_raw.dtype == np.uint16 or img_raw.max() > 255:
                # ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°: ä¸Šä½2%ã‚’é£½å’Œã•ã›ã¦0-255ã«æ­£è¦åŒ–
                p_min, p_max = np.percentile(img_raw, (0, 98))
                img_8bit = np.clip((img_raw - p_min) * (255.0 / (p_max - p_min + 1e-5)), 0, 255).astype(np.uint8)
                
                # ãƒ¢ãƒã‚¯ãƒ­16bitãªã‚‰RGBã¸å¤‰æ›
                if len(img_8bit.shape) == 2:
                    img_bgr = cv2.cvtColor(img_8bit, cv2.COLOR_GRAY2BGR)
                else:
                    img_bgr = img_8bit
            else:
                # é€šå¸¸ã®ç”»åƒã¯ã‚«ãƒ©ãƒ¼èª­ã¿è¾¼ã¿
                img_bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

            # ä»¥é™ã®å‡¦ç†ã¯å…ƒã®ã‚³ãƒ¼ãƒ‰é€šã‚Š
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
            
            val, unit = 0.0, ""
            res_display = img_rgb.copy()
            
            # --- è¦–é‡é¢ç©ã®è¨ˆç®— ---
            fov_area_mm2 = 0.0
            if scale_val > 0:
                h, w = img_rgb.shape[:2]
                fov_area_mm2 = (h * w) * ((scale_val / 1000) ** 2)

            # --- è§£æãƒ­ã‚¸ãƒƒã‚¯ ---
            # 1. é¢ç©ç‡ (Area)
            if mode == "1. å˜è‰²é¢ç©ç‡ (Area)" or (mode.startswith("5.") and trend_metric == "é¢ç©ç‡ (Area)"):
                mask = get_mask(img_hsv, target_a, sens_a, bright_a)
                val = (cv2.countNonZero(mask) / (img_rgb.shape[0] * img_rgb.shape[1])) * 100
                unit = f"% Area"
                res_display = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)
                res_display[:, :, 0] = 0
                res_display[:, :, 2] = 0
                
                real_area_str = ""
                if fov_area_mm2 > 0:
                    real_area = fov_area_mm2 * (val / 100)
                    real_area_str = f"{real_area:.4f} mmÂ²"

            # 2. ã‚«ã‚¦ãƒ³ãƒˆ (Count)
            elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
                gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                _, th = cv2.threshold(gray, bright_count, 255, cv2.THRESH_BINARY)
                blur = cv2.GaussianBlur(gray, (5,5), 0)
                _, otsu = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                final = cv2.bitwise_and(th, otsu)
                cnts, _ = cv2.findContours(final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                valid = [c for c in cnts if cv2.contourArea(c) > min_size]
                val, unit = len(valid), "cells"
                
                # ç´°èƒæç”» (ç·‘)
                cv2.drawContours(res_display, valid, -1, (0,255,0), 2)
                
                density_str = ""
                if scale_val > 0:
                    if 'use_roi_norm' in locals() and use_roi_norm:
                        # çµ„ç¹”ãƒã‚¹ã‚¯ç”Ÿæˆ (ç©´åŸ‹ã‚ç‰ˆ)
                        mask_roi = get_tissue_mask(img_hsv, roi_color, sens_roi, bright_roi)
                        roi_pixel_count = cv2.countNonZero(mask_roi)
                        real_roi_area_mm2 = roi_pixel_count * ((scale_val / 1000) ** 2)
                        
                        if real_roi_area_mm2 > 0:
                            density = val / real_roi_area_mm2
                            density_str = f"{int(density):,} cells/mmÂ² (ROI)"
                            
                            # åˆ†æ¯ã‚¨ãƒªã‚¢ã‚’èµ¤æ ã§æç”»
                            roi_cnts, _ = cv2.findContours(mask_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                            cv2.drawContours(res_display, roi_cnts, -1, (255,0,0), 3) 
                        else:
                            density_str = "ROI Area is 0"

                    elif fov_area_mm2 > 0:
                        density = val / fov_area_mm2
                        density_str = f"{int(density):,} cells/mmÂ² (FOV)"

            # 3. å…±å±€åœ¨ (Coloc)
            elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)" or (mode.startswith("5.") and trend_metric == "å…±å±€åœ¨ç‡ (Colocalization)"):
                mask_a = get_mask(img_hsv, target_a, sens_a, bright_a)
                mask_b = get_mask(img_hsv, target_b, sens_b, bright_b)
                coloc = cv2.bitwise_and(mask_a, mask_b)
                denom = cv2.countNonZero(mask_a)
                val = (cv2.countNonZero(coloc) / denom * 100) if denom > 0 else 0
                unit = f"% Coloc"
                res_display = cv2.merge([mask_b, mask_a, np.zeros_like(mask_a)])
            
            # 4. è·é›¢ (Distance)
            elif mode == "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
                mask_a = get_mask(img_hsv, target_a, sens_common, bright_common)
                mask_b = get_mask(img_hsv, target_b, sens_common, bright_common)
                pts_a, pts_b = get_centroids(mask_a), get_centroids(mask_b)
                
                if pts_a and pts_b:
                    # ãƒ”ã‚¯ã‚»ãƒ«è·é›¢ç®—å‡º
                    val_px = np.mean([np.min([np.linalg.norm(pa - pb) for pb in pts_b]) for pa in pts_a])
                    
                    # ã‚¹ã‚±ãƒ¼ãƒ«æ›ç®—
                    if scale_val > 0:
                        val = val_px * scale_val
                        unit = "Î¼m Dist"
                    else:
                        val = val_px
                        unit = "px Dist"
                else: 
                    val = 0
                    unit = "Dist"
                
                res_display = cv2.addWeighted(img_rgb, 0.6, cv2.merge([mask_a, mask_b, np.zeros_like(mask_a)]), 0.4, 0)
            
            val = max(0.0, val)

            # =========================================================
            # â˜…ã€ä¿®æ­£ã€‘ãƒ•ã‚¡ã‚¤ãƒ«å(Image_Name)ã‚’CSVã«è¿½åŠ 
            # =========================================================
            entry = {
                "Image_Name": file.name,   # <--- ã“ã“ã§ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿å­˜
                "Group": sample_group,
                "Value": val,
                "Unit": unit,
                "Is_Trend": mode.startswith("5."),
                "Ratio_Value": ratio_val if mode.startswith("5.") else 0
            }
            batch_results.append(entry)
            
            with st.expander(f"ğŸ“· Image {i+1}: {file.name}", expanded=True):
                st.markdown(f"### Result: **{val:.2f} {unit}**")
                
                if mode == "1. å˜è‰²é¢ç©ç‡ (Area)" and scale_val > 0:
                    st.metric("å®Ÿçµ„ç¹”é¢ç©", real_area_str)
                elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)" and scale_val > 0:
                    st.metric("ç´°èƒå¯†åº¦", density_str)

                c1, c2 = st.columns(2)
                c1.image(img_rgb, caption="Original (Auto-Scaled)", use_container_width=True)
                c2.image(res_display, caption="Analyzed", use_container_width=True)

    if st.button(f"ãƒ‡ãƒ¼ã‚¿ {len(batch_results)} ä»¶ã‚’è¿½åŠ ", type="primary"):
        st.session_state.analysis_history.extend(batch_results)
        st.rerun()

# ---------------------------------------------------------
# 4. ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# ---------------------------------------------------------
if st.session_state.analysis_history:
    st.divider()
    st.header("ğŸ’¾ Data Export")
    df = pd.DataFrame(st.session_state.analysis_history)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’CSVä¿å­˜ã—ã‚„ã™ãæ•´å½¢ï¼ˆåˆ—ã®ä¸¦ã³æ›¿ãˆï¼‰
    # Image_Nameã‚’ä¸€ç•ªå·¦ã«æŒã£ã¦ãã‚‹
    cols = ["Image_Name", "Group", "Value", "Unit", "Is_Trend", "Ratio_Value"]
    # å­˜åœ¨ã—ãªã„ã‚«ãƒ©ãƒ ãŒã‚ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã§ã€å®Ÿéš›ã«ã‚ã‚‹ã‚‚ã®ã ã‘ã§å†æ§‹æˆ
    cols = [c for c in cols if c in df.columns]
    df = df[cols]

    df["Value"] = df["Value"].clip(lower=0) 
    now = datetime.datetime.now() + datetime.timedelta(hours=9)
    file_name = f"quantified_data_{now.strftime('%Y%m%d_%H%M%S')}.csv"
    st.dataframe(df, use_container_width=True)
    st.download_button("ğŸ“¥ CSVãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜", df.to_csv(index=False).encode('utf-8'), file_name, "text/csv")
