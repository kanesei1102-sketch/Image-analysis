import streamlit as st
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Bio-Image Quantifier Pro", layout="wide")

if "analysis_history" not in st.session_state:
    st.session_state.analysis_history = []

st.title("ğŸ”¬ Bio-Image Quantifier: Universal Multi-Channel Edition")
st.caption("2025å¹´å®Œé‚ä»•æ§˜ï¼šå…¨è‰²å¯¾å¿œã®å…±å±€åœ¨ãƒ»ç©ºé–“è·é›¢ãƒ»çµ±è¨ˆè§£æã‚¨ãƒ³ã‚¸ãƒ³")

# --- è‰²å®šç¾©ã®è¾æ›¸ ---
COLOR_MAP = {
    "èŒ¶è‰² (DAB)": {"lower": np.array([10, 50, 20]), "upper": np.array([30, 255, 255])},
    "ç·‘ (GFP)": {"lower": np.array([35, 50, 50]), "upper": np.array([85, 255, 255])},
    "èµ¤ (RFP)": {"lower": np.array([0, 50, 50]), "upper": np.array([10, 255, 255])},
    "é’ (DAPI)": {"lower": np.array([100, 50, 50]), "upper": np.array([130, 255, 255])}
}

def get_mask(hsv_img, color_name, sens):
    conf = COLOR_MAP[color_name]
    l = np.clip(conf["lower"] - sens, 0, 255)
    u = np.clip(conf["upper"] + sens, 0, 255)
    return cv2.inRange(hsv_img, l, u)

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("Analysis Recipe")
    mode = st.selectbox("è§£æãƒ¢ãƒ¼ãƒ‰:", [
        "1. å˜è‰²é¢ç©ç‡ (Area)",
        "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)",
        "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)",
        "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)"
    ])
    sample_group = st.text_input("ã‚°ãƒ«ãƒ¼ãƒ—å (Xè»¸):", value="Control")
    st.divider()

    if mode == "1. å˜è‰²é¢ç©ç‡ (Area)":
        target_a = st.selectbox("è§£æã™ã‚‹è‰²:", list(COLOR_MAP.keys()))
        sens_a = st.slider("æ„Ÿåº¦", 10, 100, 40)
    
    elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
        min_size = st.slider("æœ€å°ç´°èƒã‚µã‚¤ã‚º (px)", 10, 500, 50)

    elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)":
        st.info("2ã¤ã®è‰²ã®é‡ãªã‚Šã‚’è§£æã—ã¾ã™")
        target_a = st.selectbox("ãƒãƒ£ãƒ³ãƒãƒ«A (åŸºæº–):", list(COLOR_MAP.keys()), index=1)
        sens_a = st.slider("ãƒãƒ£ãƒ³ãƒãƒ«Aæ„Ÿåº¦", 10, 100, 40)
        target_b = st.selectbox("ãƒãƒ£ãƒ³ãƒãƒ«B (å¯¾è±¡):", list(COLOR_MAP.keys()), index=2)
        sens_b = st.slider("ãƒãƒ£ãƒ³ãƒãƒ«Bæ„Ÿåº¦", 10, 100, 40)

    elif mode == "4. ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
        st.info("ãƒãƒ£ãƒ³ãƒãƒ«Aã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«Bã¸ã®æœ€çŸ­è·é›¢")
        target_a = st.selectbox("èµ·ç‚¹ã¨ãªã‚‹è‰²(A):", list(COLOR_MAP.keys()), index=2)
        sens_a = st.slider("èµ·ç‚¹Aæ„Ÿåº¦", 10, 100, 40)
        target_b = st.selectbox("å¯¾è±¡ã¨ãªã‚‹è‰²(B):", list(COLOR_MAP.keys()), index=3)
        sens_b = st.slider("å¯¾è±¡Bæ„Ÿåº¦", 10, 100, 40)

    if st.button("å±¥æ­´ã‚’ã™ã¹ã¦å‰Šé™¤"):
        st.session_state.analysis_history = []
        st.rerun()

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---
uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰...", type=["jpg", "png", "tif"])

if uploaded_file:
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, 1)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    
    val, unit, res_display = 0.0, "", img_rgb.copy()

    # 1. é¢ç©ç‡
    if mode == "1. å˜è‰²é¢ç©ç‡ (Area)":
        mask = get_mask(img_hsv, target_a, sens_a)
        val = (cv2.countNonZero(mask) / (img.shape[0] * img.shape[1])) * 100
        unit = f"% ({target_a})"
        res_display = mask

    # 2. ã‚«ã‚¦ãƒ³ãƒˆ
    elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(cv2.GaussianBlur(gray,(5,5),0), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
        cnts, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        valid = [c for c in cnts if cv2.contourArea(c) > min_size]
        val, unit = len(valid), "cells"
        cv2.drawContours(res_display, valid, -1, (0,255,0), 2)

    # 3. æ±ç”¨å…±å±€åœ¨
    elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)":
        mask_a = get_mask(img_hsv, target_a, sens_a)
        mask_b = get_mask(img_hsv, target_b, sens_b)
        coloc = cv2.bitwise_and(mask_a, mask_b)
        val = (cv2.countNonZero(coloc) / cv2.countNonZero(mask_a) * 100) if cv2.countNonZero(mask_a) > 0 else 0
        unit = f"% ({target_b} in {target_a})"
        # Aã‚’ç·‘ã€Bã‚’èµ¤ã¨ã—ã¦åˆæˆè¡¨ç¤ºï¼ˆé»„è‰²ãŒå…±å±€åœ¨ï¼‰
        res_display = cv2.merge([mask_b, mask_a, np.zeros_like(mask_a)])

    # 4. ç©ºé–“è·é›¢
    elif mode == "4. ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
        mask_a = get_mask(img_hsv, target_a, sens_a)
        mask_b = get_mask(img_hsv, target_b, sens_b)
        def get_pts(m):
            c, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            p = []
            for cnt in c:
                M = cv2.moments(cnt)
                if M["m00"] != 0: p.append(np.array([M["m10"]/M["m00"], M["m01"]/M["m00"]]))
            return p
