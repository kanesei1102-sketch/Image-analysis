import streamlit as st
import cv2
import numpy as np
import pandas as pd
import datetime  # JSTæ—¥æ™‚å–å¾—ç”¨

# ---------------------------------------------------------
# 0. ãƒšãƒ¼ã‚¸è¨­å®š
# ---------------------------------------------------------
st.set_page_config(page_title="Bio-Image Quantifier Pro (Fixed)", layout="wide")

if "analysis_history" not in st.session_state:
    st.session_state.analysis_history = []

# ---------------------------------------------------------
# 1. é–¢æ•°å®šç¾©
# ---------------------------------------------------------
COLOR_MAP = {
    "èŒ¶è‰² (DAB)": {"lower": np.array([10, 50, 20]), "upper": np.array([30, 255, 255])},
    "ç·‘ (GFP)": {"lower": np.array([35, 50, 50]), "upper": np.array([85, 255, 255])},
    "èµ¤ (RFP)": {"lower": np.array([0, 50, 50]), "upper": np.array([10, 255, 255])},
    "é’ (DAPI)": {"lower": np.array([100, 50, 50]), "upper": np.array([140, 255, 255])}
}

def get_mask(hsv_img, color_name, sens, bright_min):
    if color_name == "èµ¤ (RFP)":
        lower1 = np.array([0, 30, bright_min])
        upper1 = np.array([10 + sens//2, 255, 255])
        lower2 = np.array([170 - sens//2, 30, bright_min])
        upper2 = np.array([180, 255, 255])
        return cv2.inRange(hsv_img, lower1, upper1) | cv2.inRange(hsv_img, lower2, upper2)
    else:
        conf = COLOR_MAP[color_name]
        l = np.clip(conf["lower"] - sens, 0, 255)
        u = np.clip(conf["upper"] + sens, 0, 255)
        l[2] = max(l[2], bright_min)
        return cv2.inRange(hsv_img, l, u)

def get_tissue_mask(hsv_img, color_name, sens, bright_min):
    mask = get_mask(hsv_img, color_name, sens, bright_min)
    kernel = np.ones((15, 15), np.uint8) 
    mask_closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
    cnts, _ = cv2.findContours(mask_closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    mask_filled = np.zeros_like(mask)
    valid_tissue = [c for c in cnts if cv2.contourArea(c) > 500]
    cv2.drawContours(mask_filled, valid_tissue, -1, 255, thickness=cv2.FILLED)
    return mask_filled

def get_centroids(mask):
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    pts = []
    for c in cnts:
        M = cv2.moments(c)
        if M["m00"] != 0:
            pts.append(np.array([M["m10"]/M["m00"], M["m01"]/M["m00"]]))
    return pts

# ---------------------------------------------------------
# 2. ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­è¨ˆ
# ---------------------------------------------------------
st.title("ğŸ”¬ Bio-Image Quantifier: Pro Edition")
st.caption("2026å¹´æœ€æ–°ç‰ˆï¼šè§£æãƒ»ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå°‚ç”¨ (Scale: 1.5267 Î¼m/px)")

tab_main, tab_val = st.tabs(["ğŸš€ è§£æå®Ÿè¡Œ (Image Analysis)", "ğŸ† æ€§èƒ½è¨¼æ˜ (Validation Report)"])

# ---------------------------------------------------------
# 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
# ---------------------------------------------------------
with st.sidebar:
    st.markdown("### ã€Notice / ã”æ¡ˆå†…ã€‘")
    st.info("""
    This tool is a beta version. If you plan to use results from this tool in your publications or conference presentations, **please contact the developer (Seiji Kaneko) in advance.**

    æœ¬ãƒ„ãƒ¼ãƒ«ã¯ç¾åœ¨é–‹ç™ºä¸­ã®ãƒ™ãƒ¼ã‚¿ç‰ˆã§ã™ã€‚è«–æ–‡æ²è¼‰ã‚„å­¦ä¼šç™ºè¡¨ç­‰ã«ä½¿ç”¨ã•ã‚Œã‚‹éš›ã¯ã€**äº‹å‰ã«é–‹ç™ºè€…ï¼ˆé‡‘å­ï¼‰ã¾ã§å¿…ãšä¸€å ±ãã ã•ã„ã€‚**

    ğŸ‘‰ **[Contact & Feedback Form / é€£çµ¡çª“å£](https://forms.gle/xgNscMi3KFfWcuZ1A)**

    We will provide guidance on validation support and proper acknowledgments/co-authorship.
    ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚µãƒãƒ¼ãƒˆã‚„ã€è¬è¾ãƒ»å…±è‘—ã®è¨˜è¼‰ã«ã¤ã„ã¦ã”æ¡ˆå†…ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚
    """)
    st.divider()

    st.header("Analysis Recipe")
    mode = st.selectbox("è§£æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ:", [
        "1. å˜è‰²é¢ç©ç‡ (Area)",
        "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)",
        "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)",
        "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)",
        "5. å‰²åˆãƒˆãƒ¬ãƒ³ãƒ‰è§£æ (Ratio Analysis)"
    ])
    st.divider()

    if mode == "5. å‰²åˆãƒˆãƒ¬ãƒ³ãƒ‰è§£æ (Ratio Analysis)":
        st.markdown("### ğŸ”¢ æ¡ä»¶è¨­å®š (Batch)")
        trend_metric = st.radio("æ¸¬å®šå¯¾è±¡:", ["å…±å±€åœ¨ç‡ (Colocalization)", "é¢ç©ç‡ (Area)"])
        ratio_val = st.number_input("æ¡ä»¶å€¤:", value=0, step=10)
        ratio_unit = st.text_input("å˜ä½:", value="%", key="unit")
        sample_group = f"{ratio_val}{ratio_unit}"
        st.info(f"ãƒ©ãƒ™ãƒ«: **{sample_group}**")
        if trend_metric == "å…±å±€åœ¨ç‡ (Colocalization)":
            c1, c2 = st.columns(2)
            with c1:
                target_a = st.selectbox("CH-A (åŸºæº–):", list(COLOR_MAP.keys()), index=3) 
                sens_a = st.slider("Aæ„Ÿåº¦", 5, 50, 20, key="t_s_a")
                bright_a = st.slider("Aè¼åº¦", 0, 255, 60, key="t_b_a")
            with c2:
                target_b = st.selectbox("CH-B (å¯¾è±¡):", list(COLOR_MAP.keys()), index=2) 
                sens_b = st.slider("Bæ„Ÿåº¦", 5, 50, 20, key="t_s_b")
                bright_b = st.slider("Bè¼åº¦", 0, 255, 60, key="t_b_b")
        else:
            target_a = st.selectbox("è§£æè‰²:", list(COLOR_MAP.keys()), index=2)
            sens_a = st.slider("æ„Ÿåº¦", 5, 50, 20, key="t_s_a")
            bright_a = st.slider("è¼åº¦", 0, 255, 60, key="t_b_a")
    else:
        sample_group = st.text_input("ã‚°ãƒ«ãƒ¼ãƒ—å (Xè»¸):", value="Control")
        st.divider()
        if mode == "1. å˜è‰²é¢ç©ç‡ (Area)":
            target_a = st.selectbox("è§£æè‰²:", list(COLOR_MAP.keys()))
            sens_a = st.slider("æ„Ÿåº¦", 5, 50, 20)
            bright_a = st.slider("è¼åº¦", 0, 255, 60)
        
        elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
            min_size = st.slider("æœ€å°ã‚µã‚¤ã‚º(px)", 10, 500, 50)
            bright_count = st.slider("ç´°èƒè¼åº¦ã—ãã„å€¤", 0, 255, 50)
            
            use_roi_norm = st.checkbox("çµ„ç¹”ã‚¨ãƒªã‚¢(CK8ãªã©)ã§å¯†åº¦ã‚’è¨ˆç®—ã™ã‚‹", value=True)
            if use_roi_norm:
                st.markdown("""
                :red[**å®Ÿéš›ã®æŸ“è‰²ã«ç”¨ã„ãŸè‰²ã‚’ãŠé¸ã³ãã ã•ã„ã€‚ãã®ä»–ã®è‰²ã§è§£æã—ã‚ˆã†ã¨ã™ã‚‹ã¨ãƒã‚¤ã‚ºãŒå½±éŸ¿ã‚’åŠã¼ã—ã€æ­£ç¢ºãªç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆãŒè¡Œãˆã¾ã›ã‚“ã€‚**]
                """)
                roi_color = st.selectbox("çµ„ç¹”ã®è‰²:", list(COLOR_MAP.keys()), index=2) 
                sens_roi = st.slider("çµ„ç¹”æ„Ÿåº¦", 5, 50, 20)
                bright_roi = st.slider("çµ„ç¹”è¼åº¦", 0, 255, 40)

        elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)":
            c1, c2 = st.columns(2)
            with c1:
                target_a = st.selectbox("CH-A:", list(COLOR_MAP.keys()), index=3)
                sens_a = st.slider("Aæ„Ÿåº¦", 5, 50, 20)
                bright_a = st.slider("Aè¼åº¦", 0, 255, 60)
            with c2:
                target_b = st.selectbox("CH-B:", list(COLOR_MAP.keys()), index=2)
                sens_b = st.slider("Bæ„Ÿåº¦", 5, 50, 20)
                bright_b = st.slider("Bè¼åº¦", 0, 255, 60)
        elif mode == "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
            target_a = st.selectbox("èµ·ç‚¹A:", list(COLOR_MAP.keys()), index=2)
            target_b = st.selectbox("å¯¾è±¡B:", list(COLOR_MAP.keys()), index=3)
            sens_common = st.slider("è‰²æ„Ÿåº¦", 5, 50, 20)
            bright_common = st.slider("è¼åº¦", 0, 255, 60)

    st.divider()
    with st.expander("ğŸ“ ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š (Calibration)", expanded=True):
        st.caption("1ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Šã®å®Ÿå¯¸ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€é¢ç©(mmÂ²)ã‚„å¯†åº¦(cells/mmÂ²)ã‚’è‡ªå‹•ç®—å‡ºã—ã¾ã™ã€‚")
        scale_val = st.number_input("1pxã®é•·ã• (Î¼m/px)", value=1.5267, format="%.4f")

    if st.button("å±¥æ­´ã‚’å…¨æ¶ˆå»"):
        st.session_state.analysis_history = []
        st.rerun()

    st.divider()
    st.caption("ã€å…è²¬äº‹é … / Disclaimerã€‘")
    st.caption("""
    æœ¬ãƒ„ãƒ¼ãƒ«ã¯ç”»åƒè§£æã®è£œåŠ©ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
    ç…§æ˜æ¡ä»¶ã‚„è¨­å®šã«ã‚ˆã‚ŠçµæœãŒå¤‰å‹•ã™ã‚‹ãŸã‚ã€æœ€çµ‚çš„ãªè§£é‡ˆãŠã‚ˆã³çµè«–ã«ã¤ã„ã¦ã¯ã€
    åˆ©ç”¨è€…ãŒå°‚é–€çš„çŸ¥è¦‹ã«åŸºã¥ã„ã¦åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
    """)

# ---------------------------------------------------------
# 4. ã‚¿ãƒ–å†…å®¹ã®å®Ÿè£…
# ---------------------------------------------------------

with tab_main:
    uploaded_files = st.file_uploader("ç”»åƒã‚’ã¾ã¨ã‚ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "tif"], accept_multiple_files=True)

    if uploaded_files:
        st.success(f"{len(uploaded_files)} æšã®ç”»åƒã‚’è§£æä¸­...")
        batch_results = []
        
        for i, file in enumerate(uploaded_files):
            file.seek(0)
            file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
            img_bgr = cv2.imdecode(file_bytes, 1)
            
            if img_bgr is not None:
                img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
                img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
                
                val, unit = 0.0, ""
                res_display = img_rgb.copy()
                
                fov_area_mm2 = 0.0
                if scale_val > 0:
                    h, w = img_rgb.shape[:2]
                    fov_area_mm2 = (h * w) * ((scale_val / 1000) ** 2)

                # 1. Area
                if mode == "1. å˜è‰²é¢ç©ç‡ (Area)" or (mode.startswith("5.") and trend_metric == "é¢ç©ç‡ (Area)"):
                    mask = get_mask(img_hsv, target_a, sens_a, bright_a)
                    val = (cv2.countNonZero(mask) / (img_rgb.shape[0] * img_rgb.shape[1])) * 100
                    unit = f"% Area"
                    res_display = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGB)
                    res_display[:, :, 0] = 0; res_display[:, :, 2] = 0
                    real_area_str = ""
                    if fov_area_mm2 > 0:
                        real_area = fov_area_mm2 * (val / 100)
                        real_area_str = f"{real_area:.4f} mmÂ²"

                # 2. Count
                elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
                    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                    _, th = cv2.threshold(gray, bright_count, 255, cv2.THRESH_BINARY)
                    blur = cv2.GaussianBlur(gray, (5,5), 0)
                    _, otsu = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                    final = cv2.bitwise_and(th, otsu)
                    cnts, _ = cv2.findContours(final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    valid = [c for c in cnts if cv2.contourArea(c) > min_size]
                    val, unit = len(valid), "cells"
                    cv2.drawContours(res_display, valid, -1, (0,255,0), 2)
                    
                    density_str = ""
                    if scale_val > 0:
                        if 'use_roi_norm' in locals() and use_roi_norm:
                            mask_roi = get_tissue_mask(img_hsv, roi_color, sens_roi, bright_roi)
                            roi_pixel_count = cv2.countNonZero(mask_roi)
                            real_roi_area_mm2 = roi_pixel_count * ((scale_val / 1000) ** 2)
                            if real_roi_area_mm2 > 0:
                                density = val / real_roi_area_mm2
                                density_str = f"{int(density):,} cells/mmÂ² (ROI)"
                                roi_cnts, _ = cv2.findContours(mask_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                                cv2.drawContours(res_display, roi_cnts, -1, (255,0,0), 3) 
                            else:
                                density_str = "ROI Area is 0"
                        elif fov_area_mm2 > 0:
                            density = val / fov_area_mm2
                            density_str = f"{int(density):,} cells/mmÂ² (FOV)"

                # 3. Coloc
                elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)" or (mode.startswith("5.") and trend_metric == "å…±å±€åœ¨ç‡ (Colocalization)"):
                    mask_a = get_mask(img_hsv, target_a, sens_a, bright_a)
                    mask_b = get_mask(img_hsv, target_b, sens_b, bright_b)
                    coloc = cv2.bitwise_and(mask_a, mask_b)
                    denom = cv2.countNonZero(mask_a)
                    val = (cv2.countNonZero(coloc) / denom * 100) if denom > 0 else 0
                    unit = f"% Coloc"
                    res_display = cv2.merge([mask_b, mask_a, np.zeros_like(mask_a)])
                
                # 4. Distance
                elif mode == "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
                    mask_a = get_mask(img_hsv, target_a, sens_common, bright_common)
                    mask_b = get_mask(img_hsv, target_b, sens_common, bright_common)
                    pts_a, pts_b = get_centroids(mask_a), get_centroids(mask_b)
                    if pts_a and pts_b:
                        val_px = np.mean([np.min([np.linalg.norm(pa - pb) for pb in pts_b]) for pa in pts_a])
                        if scale_val > 0:
                            val = val_px * scale_val; unit = "Î¼m Dist"
                        else:
                            val = val_px; unit = "px Dist"
                    else: 
                        val = 0; unit = "Dist"
                    res_display = cv2.addWeighted(img_rgb, 0.6, cv2.merge([mask_a, mask_b, np.zeros_like(mask_a)]), 0.4, 0)
                
                val = max(0.0, val)

                # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€: ã“ã“ã§ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿å­˜ â˜…â˜…â˜…
                entry = {
                    "File Name": file.name,  # â† å¾©æ´»ï¼
                    "Group": sample_group,
                    "Value": val,
                    "Unit": unit,
                    "Is_Trend": mode.startswith("5."),
                    "Ratio_Value": ratio_val if mode.startswith("5.") else 0
                }
                batch_results.append(entry)
                
                st.divider()
                st.markdown(f"### ğŸ“· Image {i+1}: {file.name}")
                st.markdown(f"### Result: **{val:.2f} {unit}**")
                
                if mode == "1. å˜è‰²é¢ç©ç‡ (Area)" and scale_val > 0 and 'real_area_str' in locals():
                    st.metric("å®Ÿçµ„ç¹”é¢ç©", real_area_str)
                elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)" and scale_val > 0 and 'density_str' in locals():
                    st.metric("ç´°èƒå¯†åº¦", density_str)

                c1, c2 = st.columns(2)
                c1.image(img_rgb, caption="Original", use_container_width=True)
                c2.image(res_display, caption="Analyzed", use_container_width=True)

        if st.button(f"ãƒ‡ãƒ¼ã‚¿ {len(batch_results)} ä»¶ã‚’è¿½åŠ ", type="primary"):
            st.session_state.analysis_history.extend(batch_results)
            st.rerun()

    if st.session_state.analysis_history:
        st.divider()
        st.header("ğŸ’¾ Data Export")
        df = pd.DataFrame(st.session_state.analysis_history)
        df["Value"] = df["Value"].clip(lower=0) 
        
        # ã‚«ãƒ©ãƒ é †åºã®æ•´ç†ï¼ˆFile Nameã‚’å…ˆé ­ã«ï¼‰
        cols = ["File Name", "Group", "Value", "Unit", "Is_Trend", "Ratio_Value"]
        # æ—¢å­˜ã®ã‚«ãƒ©ãƒ ã ã‘ã§æ§‹æˆï¼ˆå¿µã®ãŸã‚ï¼‰
        cols = [c for c in cols if c in df.columns]
        df = df[cols]

        now = datetime.datetime.now() + datetime.timedelta(hours=9)
        file_name = f"quantified_data_{now.strftime('%Y%m%d_%H%M%S')}.csv"
        st.dataframe(df, use_container_width=True)
        st.download_button("ğŸ“¥ CSVãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜", df.to_csv(index=False).encode('utf-8'), file_name, "text/csv")

    with tab_val:
        st.header("ğŸ† æ€§èƒ½ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»æœ€çµ‚å ±å‘Š (2026 Latest)")
        st.markdown("""
        **æ¤œè¨¼ã‚½ãƒ¼ã‚¹:** [Broad Bioimage Benchmark Collection (BBBC005)](https://bbbc.broadinstitute.org/BBBC005)  
        **æ¤œè¨¼ç·æ•°:** 3,200æš (C14, C40, C70, C100 Ã— 800æš/å®Ÿæ¸¬å€¤ãƒ™ãƒ¼ã‚¹)
        """)

        # --- æœ€æ–°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ (C14-C100 å®Ÿæ¸¬å¹³å‡) ---
        m1, m2, m3 = st.columns(3)
        m1.metric("æ ¸ã‚«ã‚¦ãƒ³ãƒˆå¹³å‡ç²¾åº¦ (W1)", "97.7%", help="Focus Level 1-5ã«ãŠã‘ã‚‹å…¨å¯†åº¦å¹³å‡")
        m2.metric("çµ±è¨ˆçš„ç·šå½¢æ€§ (RÂ²)", "0.9977", help="W1å®Ÿæ¸¬å€¤(C14-C100)ã«åŸºã¥ãæ±ºå®šä¿‚æ•°")
        m3.metric("é€£ç¶šå‡¦ç†å®‰å®šæ€§", "3,200+ æš", help="800æšÃ—4ãƒãƒƒãƒå®Œé‚")

        st.divider()

        # --- 1. Linearity (ç·šå½¢æ€§) ---
        st.subheader("ğŸ“ˆ 1. è¨ˆæ•°èƒ½åŠ›ã¨ç·šå½¢æ€§ (Linearity)")
        st.info("ğŸ’¡ **çµè«–:** W1ï¼ˆæ ¸ï¼‰ã¯ $R^2=0.9977$ ã§ç†æƒ³ç·šã«è¿½å¾“ã€‚W2ï¼ˆç´°èƒä½“ï¼‰ã¯Vå­—å‹ã®ä¹–é›¢ã‚’ç¤ºã—å®šé‡ä¸é©ã€‚")
    
        # W1 vs W2 ç·šå½¢æ€§æ¯”è¼ƒã‚°ãƒ©ãƒ•
        st.image("linearity_real_c100.png", caption="Linearity Comparison: W1 (Blue) vs W2 (Orange) - Real Data C14-C100", use_container_width=True)

        st.divider()

        # --- 2. Density Comparison (å¯†åº¦åˆ¥ç²¾åº¦) ---
        st.subheader("ğŸ“Š 2. å¯†åº¦åˆ¥ç²¾åº¦æ¯”è¼ƒ (W1 vs W2)")
        st.success("âœ… **æ¨å¥¨:** å…¨å¯†åº¦é ˜åŸŸã«ãŠã„ã¦ã€ŒW1ã€ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
        st.markdown("""
        * **W1 (Nuclei):** C14ã‹ã‚‰C100ã¾ã§ã€å¸¸ã«95%ã€œ100%ã®é«˜ç²¾åº¦ã‚’ç¶­æŒã€‚
        * **W2 (Cytoplasm):** C70ã¾ã§ã¯éå°‘æ¤œå‡º (Under)ã€C100ã§ã¯135%ã®éå‰°æ¤œå‡º (Over) ã¨ãªã‚Šåˆ¶å¾¡ä¸èƒ½ã€‚
        """)
    
        # W1 vs W2 æ£’ã‚°ãƒ©ãƒ•
        st.image("w1_w2_comparison_real_c100.png", caption="Accuracy by Density: W1 Stability vs W2 Instability", use_container_width=True)

        st.divider()

        # --- 3. Focus Robustness (å…‰å­¦çš„ãªå …ç‰¢æ€§) ---
        st.subheader("ğŸ“‰ 3. å…‰å­¦çš„ãªå …ç‰¢æ€§ (Focus Robustness)")
        st.warning("âš ï¸ **æ³¨æ„:** é«˜å¯†åº¦ (C100) è§£ææ™‚ã¯ Focus Level 5 ä»¥å†…ã‚’å³å®ˆã—ã¦ãã ã•ã„ã€‚")
        st.markdown("""
        * **C14 (é’ç·š):** ãƒœã‚±ã¦ã‚‚ç²¾åº¦100%ã‚’ç¶­æŒ (Robust)ã€‚
        * **C100 (ç´«ç·š):** F5ã‚’è¶…ãˆã‚‹ã¨æ€¥æ¿€ã«ç²¾åº¦ãŒå´©å£Š (Sensitive)ã€‚
        """)
    
        # Accuracy Decay æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•
        st.image("accuracy_decay_real_c100.png", caption="Accuracy Decay by Focus Level (C14-C100 Real Data)", use_container_width=True)
